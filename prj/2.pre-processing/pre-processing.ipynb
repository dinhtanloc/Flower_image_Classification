{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:\\AIDU\\flower_classification\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "__script_path=os.path.abspath(globals().get('__file__','.'))\n",
    "__script_dir = os.path.dirname(__script_path)\n",
    "root_dir = os.path.abspath(f'{__script_dir}/../..')\n",
    "print(root_dir)\n",
    "for lib in [root_dir][::-1]:\n",
    "    if lib in sys.path:\n",
    "        sys.path.remove(lib)\n",
    "    sys.path.insert(0,lib)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:/AIDU/flower_classification\n"
     ]
    }
   ],
   "source": [
    "from libs.common import *\n",
    "from config.config import *\n",
    "from utils.utils import load_data, flower_labels, view_hist_data,view_images, plot_loss, plot_accuracy\n",
    "from models.models import VGG16, RESNET50\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(exps_dir) == False: # tạo thư mục (nếu chưa có)\n",
    "  os.makedirs(exps_dir, exist_ok=True)\n",
    "\n",
    "save_dir = f\"{exps_dir}/feature\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "test_size=0.33\n",
    "seed=42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d:/AIDU/flower_classification/data/train.csv\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(data_dir, \"train.csv\").replace(\"\\\\\", \"/\")\n",
    "test_path = os.path.join(data_dir, \"val.csv\").replace(\"\\\\\", \"/\")\n",
    "print(train_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read train data:  d:/AIDU/flower_classification/data/train.csv\n",
      "['train/carnation/6838762136_f8254d6a1a_c.jpg'\n",
      " 'train/carnation/3540544866_823aee81af_c.jpg'\n",
      " 'train/carnation/50034862576_b0f55b7b3b_c.jpg' ...\n",
      " 'train/common_daisy/26267498316_8ed1c153b4_c.jpg'\n",
      " 'train/common_daisy/50560319813_debdfea05e_c.jpg'\n",
      " 'train/common_daisy/7462259536_7f096c222f_c.jpg']\n",
      "Read valid data:  d:/AIDU/flower_classification/data/val.csv\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test)= load_data(train_path, test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_gen = ImageDataGenerator(rotation_range=30, \n",
    "                               width_shift_range=0.1,\n",
    "                               height_shift_range=0.1, \n",
    "                               rescale=1./255., \n",
    "                               shear_range=0.2, \n",
    "                               zoom_range=0.2, \n",
    "                               horizontal_flip=True, \n",
    "                               fill_mode='nearest', \n",
    "                               validation_split=0.2\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10919 images belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "target_size = (224,224)\n",
    "train_image_gen = image_gen.flow_from_directory(f'{data_dir}/train',\n",
    "                                               target_size=target_size,\n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode='categorical',\n",
    "                                               subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2723 images belonging to 14 classes.\n"
     ]
    }
   ],
   "source": [
    "valid_image_gen = image_gen.flow_from_directory(f'{data_dir}/train',\n",
    "                                               target_size=target_size,\n",
    "                                               batch_size=batch_size,\n",
    "                                               class_mode='categorical',\n",
    "                                               subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'astilbe': 0,\n",
       " 'bellflower': 1,\n",
       " 'black_eyed_susan': 2,\n",
       " 'calendula': 3,\n",
       " 'california_poppy': 4,\n",
       " 'carnation': 5,\n",
       " 'common_daisy': 6,\n",
       " 'coreopsis': 7,\n",
       " 'dandelion': 8,\n",
       " 'iris': 9,\n",
       " 'rose': 10,\n",
       " 'sunflower': 11,\n",
       " 'tulip': 12,\n",
       " 'water_lily': 13}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_gen.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  0,  0, ..., 13, 13, 13])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_image_gen.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps = 100000//batch_size\n",
    "valid_steps = 20000//batch_size\n",
    "\n",
    "# input_data_resnet = batch_images  # shape: (num_samples, 224, 224, 3)\n",
    "# input_data_vgg = batch_images     # shape: (num_samples, 224, 224, 3)\n",
    "# target_data = batch_labels \n",
    "\n",
    "\n",
    "# valid_data_resnet=valid_images\n",
    "# valid_data_vgg=valid_images\n",
    "# valid_target_data =valid_labels# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.342389968035407,\n",
       " 1: 1.1173761768317643,\n",
       " 2: 0.9885026253847546,\n",
       " 3: 0.9640649832244393,\n",
       " 4: 0.954624934429096,\n",
       " 5: 1.053957528957529,\n",
       " 6: 0.9960773581463237,\n",
       " 7: 0.9419427191166322,\n",
       " 8: 0.9385422038851642,\n",
       " 9: 0.9362888012347796,\n",
       " 10: 0.9885026253847546,\n",
       " 11: 0.9616875110093359,\n",
       " 12: 0.9419427191166322,\n",
       " 13: 0.997351114358787}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_classes = np.array(np.unique(train_image_gen.classes))\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=unique_classes, y=train_image_gen.classes)\n",
    "class_weights_dict = {i : class_weights[i] for i in range(len(class_weights))}\n",
    "np.savez(f'{save_dir}/class_weights_dict.npz', class_weights_dict = class_weights_dict)\n",
    "class_weights_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
